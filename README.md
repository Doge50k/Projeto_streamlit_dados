# Pipeline de Dados com Python, Docker e Streamlit ğŸš€

Este projeto de estudo demonstra a construÃ§Ã£o de um pipeline de dados simples e funcional. O sistema foi arquitetado para extrair dados de uma API pÃºblica, armazenÃ¡-los em um banco de dados PostgreSQL e, por fim, exibi-los em um dashboard interativo construÃ­do com Streamlit.

Todo o ambiente Ã© orquestrado com Docker e Docker Compose, garantindo que os serviÃ§os sejam isolados, reproduzÃ­veis e fÃ¡ceis de executar.

## Arquitetura do Sistema

O fluxo de dados segue uma arquitetura de serviÃ§os desacoplada, onde cada componente tem uma responsabilidade Ãºnica:

## ğŸ› ï¸ Tecnologias Utilizadas

-   **Linguagem:** Python 3.9
-   **Banco de Dados:** PostgreSQL
-   **Dashboard:** Streamlit
-   **ContainerizaÃ§Ã£o:** Docker & Docker Compose
-   **Bibliotecas Python Principais:**
    -   `requests` para as chamadas Ã  API
    -   `SQLAlchemy` para a interaÃ§Ã£o com o banco de dados
    -   `pandas` para a manipulaÃ§Ã£o dos dados no dashboard
    -   `python-dotenv` para o gerenciamento de variÃ¡veis de ambiente

## ğŸ“ Estrutura do Projeto

A organizaÃ§Ã£o dos arquivos foi pensada para manter os serviÃ§os desacoplados:

```bash
/
â”œâ”€â”€ extractor/                # ServiÃ§o de extraÃ§Ã£o e carga (ETL)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ extract_and_load.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ dashboard/                # ServiÃ§o de visualizaÃ§Ã£o (Dashboard)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ app.py
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ img/                      # Pasta para imagens do README
â”‚   â””â”€â”€ fluxograma-colorido.png
â”‚   â””â”€â”€ dashboard-screenshot.png
â”‚
â”œâ”€â”€ .env                      # Arquivo para variÃ¡veis de ambiente (local)
â”œâ”€â”€ docker-compose.yml        # Orquestrador dos contÃªineres
â””â”€â”€ README.md                 # DocumentaÃ§Ã£o do projeto

````
## âœ… PrÃ©-requisitos
Antes de comeÃ§ar, vocÃª vai precisar ter instalado em sua mÃ¡quina:
- Docker
- Docker Compose

## ğŸš€ Como Executar o Projeto
Siga os passos abaixo para rodar a aplicaÃ§Ã£o localmente:

1. **Clone o repositÃ³rio:**

```bash
git clone https://github.com/Doge50k/Projeto_streamlit_dados.git
cd Projeto_streamlit_dados
````

2. **Crie o arquivo de variÃ¡veis de ambiente:**
Crie um arquivo chamado .env na raiz do projeto e cole o seguinte conteÃºdo. Ele serÃ¡ usado para configurar o banco de dados.

```bash
# Credenciais do PostgreSQL
POSTGRES_DB=minha_base_de_dados
POSTGRES_USER=meu_usuario
POSTGRES_PASSWORD=minha_senha
````

3. **Construa e inicie os contÃªineres:**
Este comando irÃ¡ construir as imagens Docker para cada serviÃ§o e iniciar todos os contÃªineres em segundo plano.
```bash
docker-compose up --build
````
O script de extraÃ§Ã£o rodarÃ¡ automaticamente apÃ³s o banco de dados estar pronto.

4. **Acesse o Dashboard:**
ApÃ³s a inicializaÃ§Ã£o dos contÃªineres, abra seu navegador e acesse:
[http://localhost:8501](http://localhost:8501)

6. **Para para a aplicaÃ§Ã£o:**
Para parar todos os contÃªineres, pressione Ctrl + C no terminal onde o docker-compose estÃ¡ rodando, ou execute o seguinte comando em outro terminal (na mesma pasta):
```bash
docker-compose down
````

## ğŸ’¡ PrÃ³ximos Passos
Este projeto serve como uma base sÃ³lida. Algumas melhorias e prÃ³ximos passos possÃ­veis incluem:

- [ ] Agendar a execuÃ§Ã£o do script de extraÃ§Ã£o periodicamente (usando cron ou um orquestrador como Airflow).
- [ ] Adicionar tratamento de erros e um sistema de logs mais robusto.
- [ ] Implementar testes unitÃ¡rios e de integraÃ§Ã£o.
- [ ] Adicionar mais filtros e grÃ¡ficos interativos ao dashboard.
- [ ] Criar um pipeline de CI/CD para automatizar o deploy.

Feito por [Elias](https://github.com/Doge50k)
